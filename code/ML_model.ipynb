{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T06:00:21.568935Z",
     "start_time": "2020-01-27T06:00:21.561854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivek/opt/anaconda3/envs/mingqian/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vivek/opt/anaconda3/envs/mingqian/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vivek/opt/anaconda3/envs/mingqian/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vivek/opt/anaconda3/envs/mingqian/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vivek/opt/anaconda3/envs/mingqian/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vivek/opt/anaconda3/envs/mingqian/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.models\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1603183, 11)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "loadname='./data_for_ML/WSS_sample 1.txt'\n",
    "a1 = np.loadtxt(loadname)\n",
    "loadname='./data_for_ML/WSS_sample 2.txt'\n",
    "a2 = np.loadtxt(loadname)\n",
    "loadname='./data_for_ML/WSS_sample 3.txt'\n",
    "a3 = np.loadtxt(loadname)\n",
    "loadname='./data_for_ML/WSS_sample 4.txt'\n",
    "a4 = np.loadtxt(loadname)\n",
    "loadname='./data_for_ML/WSS_sample 5.txt'\n",
    "a5 = np.loadtxt(loadname)\n",
    "loadname='./data_for_ML/WSS_sample 6.txt'\n",
    "a6 = np.loadtxt(loadname)\n",
    "#loadname='./data_for_ML/WSS_sample 7_non_newtonian1.txt' # since for one case we consider non-newtonian data\n",
    "loadname='./data_for_ML/WSS_sample 7.txt'\n",
    "a7 = np.loadtxt(loadname)\n",
    "\n",
    "print(np.shape(a4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6471157, 11)\n",
      "(1043292, 11)\n"
     ]
    }
   ],
   "source": [
    "data = np.vstack((a1,a2,a3,a4,a5,a6,a7))\n",
    "data_1 = data[:,6:9]\n",
    "data_train = np.vstack((a2,a3,a4,a5,a6,a7))\n",
    "data_train_1 = data_train[:,6:9]\n",
    "data_test = a1\n",
    "print(np.shape(data_train))\n",
    "print(np.shape(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270567, 11)\n",
      "(6200590, 11)\n",
      "[ 2.6300e+02  6.8700e+02  2.0000e+00  1.0809e+03  1.3601e+00  1.0000e+01\n",
      " -2.4731e-01  1.5494e+01  1.0256e+04 -1.8819e-01  0.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "data_train_p = data_train[data_train[:,-1]==1,:]#data from pruned vessels, p=pruned\n",
    "data_train_up = data_train[data_train[:,-1]==0,:]#data from unpruned vessels, up=unpruned\n",
    "print(np.shape(data_train_p))\n",
    "print(np.shape(data_train_up))\n",
    "print(data_train_up[1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270567, 3)\n",
      "(270567, 1)\n",
      "20382.0\n",
      "[0.61808468 1.15591058 1.13433422]\n",
      "[-2.5030357   0.16406289  0.        ]\n",
      "[0.56266494 1.         1.        ]\n",
      "[-1.          0.16406289  0.08317143]\n",
      "[0.51543755 0.92428644 1.34986753]\n",
      "[-1.1441755   0.16406289  0.02778432]\n"
     ]
    }
   ],
   "source": [
    "#data for training 0-2:coordinate data; 3-5:cylinder coordinate data; \n",
    "#6:local WSS(alphat); 7:vessel radius; 8:pressure drop; 9: scalar(not correct); 10: prune or not\n",
    "x_train_p = data_train_p[:,6:9]  #x is input\n",
    "x_train_up = data_train_up[:,6:9]\n",
    "x_test = data_test[:,6:9]\n",
    "\n",
    "y_train_p = data_train_p[:,10:11]  # y is output\n",
    "y_train_up = data_train_up[:,10:11]\n",
    "y_test = data_test[:,10:11]\n",
    "\n",
    "#normalization\n",
    "x_normal=abs(x_train_p)\n",
    "x_normal=x_normal.max(axis=0)\n",
    "x_train_p = x_train_p/x_normal\n",
    "x_train_up = x_train_up/x_normal\n",
    "x_test = x_test/x_normal\n",
    "\n",
    "print(np.shape(x_train_p))\n",
    "print(np.shape(y_train_p))\n",
    "print(x_normal.max(axis=0))\n",
    "print(x_train_up.max(axis=0))\n",
    "print(x_train_up.min(axis=0))\n",
    "print(x_train_p.max(axis=0))\n",
    "print(x_train_p.min(axis=0))\n",
    "print(x_test.max(axis=0))\n",
    "print(x_test.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T06:00:40.561552Z",
     "start_time": "2020-01-27T06:00:40.191781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28602769  0.73010861  0.5060838 ]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "index = 4000\n",
    "\n",
    "print(x_train_up[index,:])\n",
    "print(y_train_up[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T06:22:06.666276Z",
     "start_time": "2020-01-27T06:22:06.593715Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07699101  0.34670371  0.43433422]\n",
      " [-0.37322918  0.50289846  0.7921205 ]\n",
      " [-0.25414879  0.56548371  0.45841919]\n",
      " [ 0.02557678  0.4878631   0.51064665]\n",
      " [-0.42878653  0.47702071  1.05156511]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[ 2.8400e+02  5.3700e+02  9.0000e+00  8.7949e+02  1.2856e+00  3.0000e+00\n",
      "   9.5107e-02  5.4904e+00  8.8526e+03 -1.0846e-01  0.0000e+00]\n",
      " [ 3.1700e+02  3.6700e+02  1.4000e+01  6.8679e+02  1.1566e+00  2.0000e+00\n",
      "  -4.6105e-01  7.9639e+00  1.6145e+04 -8.7999e-02  0.0000e+00]\n",
      " [ 3.9300e+02  2.4500e+02  1.0000e+01  6.4420e+02  9.8446e-01  2.0000e+00\n",
      "  -3.1395e-01  8.9550e+00  9.3435e+03  2.3542e-02  0.0000e+00]\n",
      " [ 3.4800e+02  6.3000e+02  1.8000e+01  1.0502e+03  1.2701e+00  6.0000e+00\n",
      "   3.1595e-02  7.7258e+00  1.0408e+04 -1.8470e-01  0.0000e+00]\n",
      " [ 3.1000e+02  2.0000e+00  1.2000e+01  4.0414e+02  8.4107e-01  0.0000e+00\n",
      "  -5.2968e-01  7.5541e+00  2.1433e+04  3.5629e-02  0.0000e+00]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "rand_arr = np.arange(x_train_up.shape[0])\n",
    " \n",
    "np.random.shuffle(rand_arr)\n",
    "print(x_train_up[rand_arr[0:5]])\n",
    "print(y_train_up[rand_arr[0:5]])\n",
    "print(data_train_up[rand_arr[0:5]])\n",
    "print(y_train_p.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_model(input_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units=1, input_dim=input_dim, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3  # input features\n",
    "nn = simple_linear_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270567\n"
     ]
    }
   ],
   "source": [
    "lenth_pru=len(data_train_p)\n",
    "print(lenth_pru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T07:25:43.553688Z",
     "start_time": "2020-01-27T07:25:13.852613Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 2us/step - loss: 0.6768 - acc: 0.5860 - val_loss: 0.7751 - val_acc: 0.2539\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6761 - acc: 0.5884 - val_loss: 0.7803 - val_acc: 0.2419\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6754 - acc: 0.5902 - val_loss: 0.7859 - val_acc: 0.2290\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6748 - acc: 0.5919 - val_loss: 0.7914 - val_acc: 0.2172\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6742 - acc: 0.5931 - val_loss: 0.7959 - val_acc: 0.2077\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6736 - acc: 0.5941 - val_loss: 0.7981 - val_acc: 0.2027\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6730 - acc: 0.5952 - val_loss: 0.8010 - val_acc: 0.1969\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6724 - acc: 0.5967 - val_loss: 0.8034 - val_acc: 0.1919\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6719 - acc: 0.5982 - val_loss: 0.8051 - val_acc: 0.1883\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6713 - acc: 0.5995 - val_loss: 0.8070 - val_acc: 0.1847\n",
      "1\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6711 - acc: 0.5993 - val_loss: 0.8084 - val_acc: 0.1823\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6706 - acc: 0.6005 - val_loss: 0.8098 - val_acc: 0.1800\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6701 - acc: 0.6019 - val_loss: 0.8100 - val_acc: 0.1797\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6695 - acc: 0.6032 - val_loss: 0.8100 - val_acc: 0.1798\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6690 - acc: 0.6044 - val_loss: 0.8111 - val_acc: 0.1781\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6685 - acc: 0.6055 - val_loss: 0.8112 - val_acc: 0.1780\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6680 - acc: 0.6067 - val_loss: 0.8117 - val_acc: 0.1776\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6675 - acc: 0.6076 - val_loss: 0.8122 - val_acc: 0.1768\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6669 - acc: 0.6089 - val_loss: 0.8109 - val_acc: 0.1788\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6664 - acc: 0.6102 - val_loss: 0.8097 - val_acc: 0.1806\n",
      "2\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6656 - acc: 0.6127 - val_loss: 0.8101 - val_acc: 0.1801\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6651 - acc: 0.6138 - val_loss: 0.8104 - val_acc: 0.1796\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6646 - acc: 0.6149 - val_loss: 0.8108 - val_acc: 0.1792\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6641 - acc: 0.6162 - val_loss: 0.8115 - val_acc: 0.1783\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6636 - acc: 0.6174 - val_loss: 0.8121 - val_acc: 0.1775\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6631 - acc: 0.6185 - val_loss: 0.8134 - val_acc: 0.1757\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6627 - acc: 0.6195 - val_loss: 0.8150 - val_acc: 0.1736\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6622 - acc: 0.6204 - val_loss: 0.8167 - val_acc: 0.1714\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6617 - acc: 0.6214 - val_loss: 0.8182 - val_acc: 0.1697\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6612 - acc: 0.6226 - val_loss: 0.8192 - val_acc: 0.1685\n",
      "3\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6607 - acc: 0.6234 - val_loss: 0.8192 - val_acc: 0.1689\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6603 - acc: 0.6248 - val_loss: 0.8201 - val_acc: 0.1680\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6598 - acc: 0.6261 - val_loss: 0.8203 - val_acc: 0.1683\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6593 - acc: 0.6275 - val_loss: 0.8211 - val_acc: 0.1677\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6589 - acc: 0.6285 - val_loss: 0.8204 - val_acc: 0.1690\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6584 - acc: 0.6295 - val_loss: 0.8195 - val_acc: 0.1706\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6580 - acc: 0.6307 - val_loss: 0.8185 - val_acc: 0.1723\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6575 - acc: 0.6319 - val_loss: 0.8187 - val_acc: 0.1726\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6571 - acc: 0.6332 - val_loss: 0.8209 - val_acc: 0.1707\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6566 - acc: 0.6344 - val_loss: 0.8234 - val_acc: 0.1686\n",
      "4\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6561 - acc: 0.6364 - val_loss: 0.8252 - val_acc: 0.1671\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6557 - acc: 0.6376 - val_loss: 0.8245 - val_acc: 0.1686\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6553 - acc: 0.6387 - val_loss: 0.8248 - val_acc: 0.1690\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6548 - acc: 0.6399 - val_loss: 0.8231 - val_acc: 0.1717\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6544 - acc: 0.6409 - val_loss: 0.8226 - val_acc: 0.1731\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6540 - acc: 0.6419 - val_loss: 0.8219 - val_acc: 0.1745\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6536 - acc: 0.6429 - val_loss: 0.8230 - val_acc: 0.1739\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6532 - acc: 0.6442 - val_loss: 0.8245 - val_acc: 0.1730\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6527 - acc: 0.6456 - val_loss: 0.8250 - val_acc: 0.1733\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6523 - acc: 0.6467 - val_loss: 0.8241 - val_acc: 0.1753\n",
      "5\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6520 - acc: 0.6471 - val_loss: 0.8232 - val_acc: 0.1770\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6516 - acc: 0.6481 - val_loss: 0.8236 - val_acc: 0.1775\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6512 - acc: 0.6491 - val_loss: 0.8237 - val_acc: 0.1783\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6508 - acc: 0.6506 - val_loss: 0.8265 - val_acc: 0.1765\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6504 - acc: 0.6523 - val_loss: 0.8293 - val_acc: 0.1748\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6500 - acc: 0.6537 - val_loss: 0.8301 - val_acc: 0.1750\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6496 - acc: 0.6546 - val_loss: 0.8287 - val_acc: 0.1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6492 - acc: 0.6553 - val_loss: 0.8282 - val_acc: 0.1789\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6488 - acc: 0.6559 - val_loss: 0.8259 - val_acc: 0.1822\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6484 - acc: 0.6565 - val_loss: 0.8241 - val_acc: 0.1850\n",
      "6\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6478 - acc: 0.6580 - val_loss: 0.8249 - val_acc: 0.1852\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6474 - acc: 0.6590 - val_loss: 0.8270 - val_acc: 0.1839\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6470 - acc: 0.6602 - val_loss: 0.8283 - val_acc: 0.1835\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6466 - acc: 0.6612 - val_loss: 0.8293 - val_acc: 0.1834\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6462 - acc: 0.6619 - val_loss: 0.8299 - val_acc: 0.1836\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6459 - acc: 0.6626 - val_loss: 0.8303 - val_acc: 0.1840\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6455 - acc: 0.6634 - val_loss: 0.8287 - val_acc: 0.1866\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6451 - acc: 0.6641 - val_loss: 0.8276 - val_acc: 0.1886\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6447 - acc: 0.6647 - val_loss: 0.8277 - val_acc: 0.1891\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6444 - acc: 0.6652 - val_loss: 0.8286 - val_acc: 0.1891\n",
      "7\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6440 - acc: 0.6652 - val_loss: 0.8282 - val_acc: 0.1901\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6437 - acc: 0.6658 - val_loss: 0.8288 - val_acc: 0.1903\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6433 - acc: 0.6661 - val_loss: 0.8285 - val_acc: 0.1913\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6429 - acc: 0.6667 - val_loss: 0.8304 - val_acc: 0.1903\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6426 - acc: 0.6670 - val_loss: 0.8289 - val_acc: 0.1922\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6422 - acc: 0.6675 - val_loss: 0.8302 - val_acc: 0.1918\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6419 - acc: 0.6684 - val_loss: 0.8317 - val_acc: 0.1912\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6415 - acc: 0.6688 - val_loss: 0.8315 - val_acc: 0.1921\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6412 - acc: 0.6687 - val_loss: 0.8295 - val_acc: 0.1946\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6408 - acc: 0.6686 - val_loss: 0.8303 - val_acc: 0.1947\n",
      "8\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6404 - acc: 0.6698 - val_loss: 0.8335 - val_acc: 0.1927\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6401 - acc: 0.6703 - val_loss: 0.8341 - val_acc: 0.1929\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6397 - acc: 0.6704 - val_loss: 0.8336 - val_acc: 0.1941\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6394 - acc: 0.6704 - val_loss: 0.8339 - val_acc: 0.1946\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6390 - acc: 0.6708 - val_loss: 0.8321 - val_acc: 0.1967\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6387 - acc: 0.6714 - val_loss: 0.8292 - val_acc: 0.1997\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6384 - acc: 0.6717 - val_loss: 0.8281 - val_acc: 0.2012\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6380 - acc: 0.6721 - val_loss: 0.8301 - val_acc: 0.2001\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6377 - acc: 0.6725 - val_loss: 0.8322 - val_acc: 0.1989\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6374 - acc: 0.6727 - val_loss: 0.8309 - val_acc: 0.2004\n",
      "9\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6375 - acc: 0.6723 - val_loss: 0.8320 - val_acc: 0.2001\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6372 - acc: 0.6725 - val_loss: 0.8340 - val_acc: 0.1992\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6368 - acc: 0.6729 - val_loss: 0.8331 - val_acc: 0.2005\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6365 - acc: 0.6734 - val_loss: 0.8313 - val_acc: 0.2024\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6362 - acc: 0.6738 - val_loss: 0.8303 - val_acc: 0.2035\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6359 - acc: 0.6743 - val_loss: 0.8306 - val_acc: 0.2037\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6356 - acc: 0.6746 - val_loss: 0.8312 - val_acc: 0.2037\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6353 - acc: 0.6749 - val_loss: 0.8318 - val_acc: 0.2037\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6350 - acc: 0.6752 - val_loss: 0.8343 - val_acc: 0.2027\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6347 - acc: 0.6756 - val_loss: 0.8356 - val_acc: 0.2023\n",
      "10\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6342 - acc: 0.6760 - val_loss: 0.8348 - val_acc: 0.2033\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6339 - acc: 0.6762 - val_loss: 0.8336 - val_acc: 0.2045\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6336 - acc: 0.6765 - val_loss: 0.8307 - val_acc: 0.2070\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6333 - acc: 0.6768 - val_loss: 0.8287 - val_acc: 0.2088\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6330 - acc: 0.6769 - val_loss: 0.8283 - val_acc: 0.2095\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6327 - acc: 0.6772 - val_loss: 0.8302 - val_acc: 0.2086\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6324 - acc: 0.6774 - val_loss: 0.8317 - val_acc: 0.2080\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6321 - acc: 0.6778 - val_loss: 0.8339 - val_acc: 0.2069\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6318 - acc: 0.6780 - val_loss: 0.8328 - val_acc: 0.2081\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6315 - acc: 0.6783 - val_loss: 0.8331 - val_acc: 0.2084\n",
      "11\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6313 - acc: 0.6784 - val_loss: 0.8315 - val_acc: 0.2097\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6310 - acc: 0.6789 - val_loss: 0.8325 - val_acc: 0.2093\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6307 - acc: 0.6794 - val_loss: 0.8338 - val_acc: 0.2087\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6305 - acc: 0.6797 - val_loss: 0.8322 - val_acc: 0.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6302 - acc: 0.6800 - val_loss: 0.8314 - val_acc: 0.2109\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6299 - acc: 0.6802 - val_loss: 0.8319 - val_acc: 0.2109\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6296 - acc: 0.6804 - val_loss: 0.8315 - val_acc: 0.2117\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6293 - acc: 0.6807 - val_loss: 0.8314 - val_acc: 0.2124\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6291 - acc: 0.6810 - val_loss: 0.8326 - val_acc: 0.2118\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6288 - acc: 0.6814 - val_loss: 0.8334 - val_acc: 0.2116\n",
      "12\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6284 - acc: 0.6821 - val_loss: 0.8326 - val_acc: 0.2132\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6281 - acc: 0.6825 - val_loss: 0.8311 - val_acc: 0.2166\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6279 - acc: 0.6829 - val_loss: 0.8308 - val_acc: 0.2184\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6276 - acc: 0.6832 - val_loss: 0.8319 - val_acc: 0.2180\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6273 - acc: 0.6836 - val_loss: 0.8316 - val_acc: 0.2208\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6271 - acc: 0.6840 - val_loss: 0.8313 - val_acc: 0.2233\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6268 - acc: 0.6845 - val_loss: 0.8296 - val_acc: 0.2266\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6265 - acc: 0.6850 - val_loss: 0.8293 - val_acc: 0.2276\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6263 - acc: 0.6855 - val_loss: 0.8280 - val_acc: 0.2307\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6260 - acc: 0.6858 - val_loss: 0.8296 - val_acc: 0.2299\n",
      "13\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6253 - acc: 0.6875 - val_loss: 0.8308 - val_acc: 0.2300\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6250 - acc: 0.6876 - val_loss: 0.8308 - val_acc: 0.2308\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6248 - acc: 0.6877 - val_loss: 0.8308 - val_acc: 0.2313\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6245 - acc: 0.6877 - val_loss: 0.8328 - val_acc: 0.2299\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6243 - acc: 0.6876 - val_loss: 0.8323 - val_acc: 0.2314\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6240 - acc: 0.6880 - val_loss: 0.8313 - val_acc: 0.2351\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6237 - acc: 0.6882 - val_loss: 0.8316 - val_acc: 0.2355\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6235 - acc: 0.6881 - val_loss: 0.8313 - val_acc: 0.2358\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6232 - acc: 0.6883 - val_loss: 0.8303 - val_acc: 0.2368\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6230 - acc: 0.6887 - val_loss: 0.8281 - val_acc: 0.2399\n",
      "14\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6231 - acc: 0.6883 - val_loss: 0.8276 - val_acc: 0.2407\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6229 - acc: 0.6882 - val_loss: 0.8305 - val_acc: 0.2390\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6226 - acc: 0.6883 - val_loss: 0.8324 - val_acc: 0.2383\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6224 - acc: 0.6884 - val_loss: 0.8326 - val_acc: 0.2386\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6222 - acc: 0.6886 - val_loss: 0.8325 - val_acc: 0.2390\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6219 - acc: 0.6887 - val_loss: 0.8329 - val_acc: 0.2390\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6217 - acc: 0.6888 - val_loss: 0.8321 - val_acc: 0.2404\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6214 - acc: 0.6891 - val_loss: 0.8311 - val_acc: 0.2430\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6212 - acc: 0.6893 - val_loss: 0.8307 - val_acc: 0.2444\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6210 - acc: 0.6895 - val_loss: 0.8293 - val_acc: 0.2463\n",
      "15\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6207 - acc: 0.6902 - val_loss: 0.8267 - val_acc: 0.2492\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6205 - acc: 0.6903 - val_loss: 0.8238 - val_acc: 0.2514\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6203 - acc: 0.6904 - val_loss: 0.8250 - val_acc: 0.2511\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6201 - acc: 0.6906 - val_loss: 0.8276 - val_acc: 0.2499\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6198 - acc: 0.6908 - val_loss: 0.8302 - val_acc: 0.2488\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6196 - acc: 0.6912 - val_loss: 0.8318 - val_acc: 0.2484\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6194 - acc: 0.6913 - val_loss: 0.8310 - val_acc: 0.2493\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6191 - acc: 0.6912 - val_loss: 0.8284 - val_acc: 0.2510\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6189 - acc: 0.6913 - val_loss: 0.8267 - val_acc: 0.2527\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6187 - acc: 0.6913 - val_loss: 0.8282 - val_acc: 0.2522\n",
      "16\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6183 - acc: 0.6919 - val_loss: 0.8267 - val_acc: 0.2535\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6181 - acc: 0.6918 - val_loss: 0.8253 - val_acc: 0.2549\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6178 - acc: 0.6918 - val_loss: 0.8265 - val_acc: 0.2546\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6176 - acc: 0.6922 - val_loss: 0.8274 - val_acc: 0.2546\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6174 - acc: 0.6923 - val_loss: 0.8287 - val_acc: 0.2544\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6172 - acc: 0.6924 - val_loss: 0.8291 - val_acc: 0.2546\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6170 - acc: 0.6923 - val_loss: 0.8297 - val_acc: 0.2547\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6168 - acc: 0.6922 - val_loss: 0.8284 - val_acc: 0.2559\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6165 - acc: 0.6925 - val_loss: 0.8255 - val_acc: 0.2583\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6163 - acc: 0.6927 - val_loss: 0.8265 - val_acc: 0.2581\n",
      "17\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6164 - acc: 0.6913 - val_loss: 0.8280 - val_acc: 0.2576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6162 - acc: 0.6913 - val_loss: 0.8262 - val_acc: 0.2593\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6160 - acc: 0.6915 - val_loss: 0.8269 - val_acc: 0.2593\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6158 - acc: 0.6915 - val_loss: 0.8265 - val_acc: 0.2602\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6156 - acc: 0.6917 - val_loss: 0.8250 - val_acc: 0.2619\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6154 - acc: 0.6919 - val_loss: 0.8273 - val_acc: 0.2606\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6152 - acc: 0.6919 - val_loss: 0.8284 - val_acc: 0.2603\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6150 - acc: 0.6922 - val_loss: 0.8260 - val_acc: 0.2629\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6148 - acc: 0.6923 - val_loss: 0.8233 - val_acc: 0.2657\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6146 - acc: 0.6925 - val_loss: 0.8229 - val_acc: 0.2666\n",
      "18\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6143 - acc: 0.6928 - val_loss: 0.8210 - val_acc: 0.2692\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6141 - acc: 0.6931 - val_loss: 0.8188 - val_acc: 0.2715\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6139 - acc: 0.6933 - val_loss: 0.8163 - val_acc: 0.2738\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6137 - acc: 0.6934 - val_loss: 0.8179 - val_acc: 0.2729\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6135 - acc: 0.6935 - val_loss: 0.8189 - val_acc: 0.2726\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6133 - acc: 0.6935 - val_loss: 0.8191 - val_acc: 0.2728\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6131 - acc: 0.6936 - val_loss: 0.8188 - val_acc: 0.2734\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6130 - acc: 0.6936 - val_loss: 0.8191 - val_acc: 0.2737\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6128 - acc: 0.6936 - val_loss: 0.8213 - val_acc: 0.2724\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6126 - acc: 0.6937 - val_loss: 0.8213 - val_acc: 0.2729\n",
      "19\n",
      "Train on 541134 samples, validate on 1043292 samples\n",
      "Epoch 1/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6123 - acc: 0.6941 - val_loss: 0.8198 - val_acc: 0.2744\n",
      "Epoch 2/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6121 - acc: 0.6942 - val_loss: 0.8190 - val_acc: 0.2756\n",
      "Epoch 3/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6119 - acc: 0.6942 - val_loss: 0.8196 - val_acc: 0.2756\n",
      "Epoch 4/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6117 - acc: 0.6942 - val_loss: 0.8194 - val_acc: 0.2762\n",
      "Epoch 5/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6116 - acc: 0.6943 - val_loss: 0.8181 - val_acc: 0.2777\n",
      "Epoch 6/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6114 - acc: 0.6942 - val_loss: 0.8200 - val_acc: 0.2767\n",
      "Epoch 7/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6112 - acc: 0.6942 - val_loss: 0.8189 - val_acc: 0.2780\n",
      "Epoch 8/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6110 - acc: 0.6942 - val_loss: 0.8190 - val_acc: 0.2783\n",
      "Epoch 9/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6108 - acc: 0.6942 - val_loss: 0.8188 - val_acc: 0.2789\n",
      "Epoch 10/10\n",
      "541134/541134 [==============================] - 1s 1us/step - loss: 0.6107 - acc: 0.6942 - val_loss: 0.8185 - val_acc: 0.2796\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "loss_values=np.array([0])\n",
    "vali_loss=np.array([0])\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    rand_arr = np.arange(x_train_up.shape[0]) \n",
    "    np.random.shuffle(rand_arr)\n",
    "    ran_x_train_up = x_train_up[rand_arr[0:lenth_pru]]\n",
    "    ran_y_train_up = y_train_up[rand_arr[0:lenth_pru]]\n",
    "    x_train = np.vstack((ran_x_train_up,x_train_p))\n",
    "    y_train = np.vstack((ran_y_train_up,y_train_p))\n",
    "    cost = nn.fit(x_train, y_train, epochs=10, batch_size=60000, validation_data=(x_test, y_test), verbose=1)\n",
    "    loss_values = np.hstack((loss_values,cost.history['loss']))\n",
    "    vali_loss = np.hstack((vali_loss,cost.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights (coefficients): ['0.38082656', '-2.88145518', '1.21349680']\n",
      "Bias (intercept): 0.61783278\n"
     ]
    }
   ],
   "source": [
    "# weights and bias\n",
    "weights, bias = nn.layers[0].get_weights()\n",
    "\n",
    "# Flatten weights to 1D array and format each element to 8 decimal places\n",
    "formatted_weights = [\"{:.8f}\".format(w) for w in weights.flatten()]\n",
    "formatted_bias = \"{:.8f}\".format(bias[0])\n",
    "\n",
    "# Print weights and bias\n",
    "print(\"Weights (coefficients):\", formatted_weights)\n",
    "print(\"Bias (intercept):\", formatted_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T07:25:55.156279Z",
     "start_time": "2020-01-27T07:25:54.869805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss function\n",
    "fig,ax = plt.subplots()\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "plt.plot(epochs, loss_values, label='Training Loss',linewidth=2.0)\n",
    "plt.plot(epochs, vali_loss, label='Test Loss',linewidth=2.0)\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.xlabel('Epochs',fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Loss',fontsize=16, fontweight='bold')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(1.5)\n",
    "plt.xlim(1, epochs[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend()\n",
    "linewidth=10\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6106557381221971\n",
      "0.8184893554191236\n"
     ]
    }
   ],
   "source": [
    "print(loss_values[-1])\n",
    "print(vali_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T07:25:58.010129Z",
     "start_time": "2020-01-27T07:25:56.957061Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1043292, 1)\n",
      "[0.83041024]\n",
      "[0.23414417]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(x_test)\n",
    "print(np.shape(y_pred))\n",
    "print(y_pred.max(axis=0))\n",
    "print(y_pred.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T07:26:00.528573Z",
     "start_time": "2020-01-27T07:26:00.519861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2870875]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "print(y_pred[index])\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output\n",
    "np.savetxt('output_a1.txt',y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
